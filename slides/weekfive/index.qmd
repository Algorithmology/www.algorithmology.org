---
title: "Running Time Analysis: Experimental Evaluation"
echo: true
description: "How do you use experiments to measure the performance of a Python program?"
date: "2024-02-12"
date-format: long
author: Gregory M. Kapfhammer
execute:
  freeze: auto
format:
  revealjs:
    theme: default
    css: styles.css
    history: false
    scrollable: true
    transition: slide
    highlight-style: github
    footer: "Algorithmology"
---

# Programmers must write programs that are *correct*, *efficient*, and *maintainable*

<!-- Note: the source code in this slide deck demonstrates that Quarto leverages
previously defined functions in later-defined code blocks. This means that source
code on later slides can assume existence of functions in prior slides! -->

::: fragment

- **Prior Focus**: is the program implemented correctly?
- **New Focus**: does the program have good performance?

:::

## Programmers often ask "does your program have good performance?" Here are some common answers!

::: {.incremental .fade-right}

- "Yes, it was fast enough on my laptop"
- "I think it is fast enough for most users"
- "I don't know, I never measured its performance"
- "It is really fast if you run it on an Apple M3 chip"
- "Let's wait for our user's to tell us if it is fast enough"
- "One function is too slow --- and I think we rarely use it"

:::

## A two-week road map for exploring Python program performance

::: {.fragment .fade-right style="margin-top: 0.25em; font-size: 0.95em;"}

- Week 1: **Empirical Evaluation of Running Time**

    - How do you conduct timing experiments to measure the performance of a
    real Python programs?

- Week 2: **Analytical Evaluation of Time Complexity**

    - How do you use an instruction cost model to prove that it belongs to a
    specific time complexity class?

:::

::: {.fragment .fade .boxed-content style="margin-top: -0.25em; font-size: 0.9em;"}

**Ultimate Goal**: create a nuanced description of program efficiency that
adapts to *different inputs* and to *different computers*

:::

## Algorithm analysis challenges 

::: {.columns style="margin-top: 1.25em;"}

::: {.fragment .column .fade style="margin-top: 0.25em;"}

### Different Inputs

- Varying sizes of input data
- Different types of data
- Degrees of sortedness
- Degrees of duplication
- Different data distributions

:::

::: {.fragment .column style="margin-top: 0.25em;"}

### Different Computers

- Diverse hardware setups
- Varying system performance
- Diverse system building
- Different operating systems
- Variation in system load

:::

:::

::: {.fragment .fade .boxed-content style="margin-top: -0.25em; font-size: 0.9em;"}

**Ultimate goal**: experimental and analytical evaluation methods that yield
actionable insights that support *understanding* and *prediction*

:::

# Practical methods for measuring the running time of a program

::: {.fragment .fade-right}

- Implement as a Python function with inputs and outputs
- Use the `time` module to measure running time on inputs
- Study trade-offs associated with different implementations

:::

## Implementing a duplicate detector

```{python}
from typing import List
def duplicates(input_list: List[int]) -> None:
    n = len(input_list)
    for i in range(n):
        for j in range(n):
            if i != j and input_list[i] == input_list[j]:
                return True
    return False

assert(duplicates([1,2,6,3,4,5,6,7,8]))
assert(not duplicates([1,2,3,4]))
print(duplicates([1,2,6,3,4,5,6,7,8]))
print(not duplicates([1,2,3,4]))
```

::: {.fragment .fade-left style="margin-top: -0.25em; font-size: 0.9em;"}

- Returns `True` if there are any duplicates and `False` otherwise
- What is the performance of the `duplicates` function? Why?

:::

## Performance of a duplicate detector?

::: {style="font-size: 1em;"}

```{python}
from typing import List
import time

for i in range(5):
    n = 1000
    start = time.time()
    duplicates(list(range(n)))
    time_taken = time.time() - start
    print("Time taken for n = {}: {:.15f} seconds".format(n, time_taken))
```

:::

::: {.fragment .fade-left style="margin-top: 0.25em; font-size: 0.9em;"}

- What is the strategy for calculating the elapsed time?
- Do the results suggest that this implementation is fast? Why?

:::

## General-purpose function timing

::: {style="font-size: 0.925em;"}

```{python}
from typing import Callable
import time

def timetrials(function: Callable, n: int, trials: int = 10) -> None:
    """Time the function with n inputs trials times"""
    totaltime = 0
    for _ in range(trials):
        start = time.time()
        function(list(range(n)))
        totaltime += time.time() - start
    print("average =%10.7f for n = %d" % (totaltime/trials, n))

# conduct a doubling experiment for a provided function
for n in [50, 100, 200, 400, 800, 1600, 3200]:
    timetrials(duplicates, n)
```

:::

## Duplicate detecting experiment

::: {.columns style="margin-top: 1.25em;"}

::: {.fragment .column .fade style="margin-top: 0.25em;"}

### Duplicate Function

- Accepts an input list
- `True` if duplicate found
- `False` if no duplicates
- `n` is the list's length
- Double nested `for` loop

:::

::: {.fragment .column style="margin-top: 0.25em;"}

### Timing Function

- Use the `time` module
- Calculate elapsed time
- Consistent number format
- Provide a function as input
- Run a doubling experiment

:::

:::

::: {.fragment .fade .boxed-content style="margin-top: -0.25em; font-size: 0.9em;"}

**Key Observation**: properly designed experiments yield meaningful insights into
the likely worst-case performance of a Python function

:::

# Can we improve the performance of duplicate detection?

::: {.fragment .fade-right}

- Avoid doing unnecessary computational steps
- `duplicates` compares each pair of elements twice
- Improve speed by only letting `j` range up to `i`

:::

## Improving `duplicate`'s speed

```{python}
def duplicates_restrict_range(L):
    n = len(L)
    for i in range(1,n):
        for j in range(i):
            if L[i] == L[j]:
                return True
    return False

for n in [50, 100, 200, 400, 800, 1600, 3200]:
    timetrials(duplicates_restrict_range, n)
```

::: {.fragment .fade-right}

- Did this improve the performance? How can you tell? Why?

:::

## Refactoring `duplicate` again

```{python}
def duplicates_any(input_list: List[int]):
    n = len(input_list)

    return any(input_list[i] == input_list[j]
        for i in range(1,n) for j in range(i))

for n in [50, 100, 200, 400, 800, 1600, 3200]:
    timetrials(duplicates_any, n)
```

::: {.fragment .fade-right}

- Wait, this new implementation does not seem to be faster!
- Reducing code size does not always improve performance

:::

## More alternatives to `duplicates`

```{python}
def duplicates_sort(input_list: List[int]):
    n = len(input_list)
    input_list.sort()
    for i in range(n-1):
        if input_list[i] == input_list[i+1]:
            return True
    return False

for n in [50, 100, 200, 400, 800, 1600, 3200]:
    timetrials(duplicates_sort, n)
```

::: {.fragment .fade-right}

- Does `sort` improve the performance of `duplicates`?

:::

## Using both `any` and `sort`

```{python}
def duplicates_sort_any(input_list: List[int]):
    n = len(input_list)
    input_list.sort()
    return any(input_list[i] == input_list[i+1] for i in range(n-1))

for n in [50, 100, 200, 400, 800, 1600, 3200]:
    timetrials(duplicates_sort_any, n)
```

::: {.fragment .fade-right style="margin-top: -0.25em; font-size: 0.9em;"}

- Does `sort` improve the performance of `duplicates`?
- Does the use of `any` improve or hinder performance?
- What is the connection between code size and efficiency?

:::

## Using `set` with a `for` loop

```{python}
def duplicates_set_loop(input_list: List[int]):
    s = set()
    for e in input_list:
        if e in s:
            return True
        s.add(e)
    return False

for n in [50, 100, 200, 400, 800, 1600, 3200]:
    timetrials(duplicates_set_loop, n)
```

## Using `set` without a `for` loop

```{python}
def duplicates_set(input_list: List[int]):
    return len(input_list) != len(set(input_list))

for n in [50, 100, 200, 400, 800, 1600, 3200]:
    timetrials(duplicates_set, n)
```

::: {.fragment .fade-right}

- What is the fastest approach to duplicate detection?
- How did you know that this approach was the fastest?
- Can you explain why this approach is the fastest?

:::

## Key insights from the duplicate detection experiments

::: {.incremental style="font-size: 0.9em; margin-top: -0.25em;"}

- What did we learn from these experiments?

    - Different implementations yield different performance results
    - Time overhead increases as the input size increases
    - `set` construction and containment check yield improvements
    - Benefits from assuming that data is comparable or hashable
    - Code size does not always correlate with performance

:::

::: {.fragment .fade .boxed-content style="margin-top: -0.25em; font-size: 0.9em;"}

**Algorithm Engineering**: quickly implement a doubling experiment using 
a function like `timetrials` and compare results

:::
