---
title: "Introduction to Algorithm Analysis"
description: "How can we use Python packages to characterize the runtime environment used during experiments?"
date: "2024-01-15"
date-format: long
author: Gregory M. Kapfhammer
format:
  revealjs:
    theme: default
    css: styles.css
    history: false
    scrollable: true
    transition: slide
    highlight-style: github
    footer: "Algorithmology"
---

# What is algorithm analysis?

::: incremental
- Data structures that organize data
- Algorithms that process data structures
- Experimental and theoretical analysis
- "Algorithmology" is both *science* and *engineering*
:::

## Algorithm analysis process

::: incremental
- Design, implement, and test
  - Data structures and algorithms
  - Benchmark framework
  - Data analysis tools
- Create execution environments
  - Repeatable and reproducible
  - Controlled and varied
  - Local and in the cloud
:::

## Examples of four programs to study through benchmarks

- Terminal window shell like `bash` or `zsh`
- Terminal prompt like `powerlevel10k` or `starship`
- Web browser like `firefox` or `chrome`
- Text editor like `vim` or `emacs`

::: {.fragment .fade style="margin-top: 0.25em; font-size: 0.9em;"}

> How do we characterize the execution environment of these programs?
> How do we compare their performance in different configurations?
> How do we improve their performance?

:::

## Wow, measuring and improving the performance of any complex program is very challenging!

::: {.fragment}

- Differences in the execution environment
- Difficulty in measuring the performance
- Challenging to compare the performance
- Hard to repeat and reproduce experiments
- Results change as the program evolves
- Caution needed to avoid over-optimization

:::

# How Can We Characterize the Execution Environment of a Program?

- *Sensing* properties of a system with Python
- *Characterizing* system performance with micro-benchmarks

## Using the `systemsense` tool

```{code-line-numbers="true" code-block-border="true"}
 Usage: systemsense [OPTIONS] COMMAND [ARGS]...
╭─ Commands ────────────────────────────────────────────────╮
│ benchmarkinfo  Benchmark the system used for experiments. │
│ completeinfo   Detect information about and then          │
│                benchmark the system used for experiments. │
│ systeminfo     Detect all relevant information about the  │
│                system used for experiments.               │
╰───────────────────────────────────────────────────────────╯
```

- `systeminfo`: use packages like `psutil` to collect relevant information
about the execution environment, suitable for characterizing local and
cloud-based systems
- `benchmarkinfo`: use packages like `timeit` to run simple micro-benchmarks
involving basic operations so as to characterize baseline system performance

## Detecting CPU details

```python
def get_cpu() -> Dict[str, str]:
    """Return information about the current CPU in the system."""
    # detect the name of the function in
    # which this source code exists
    function_name = inspect.stack()[0][3]
    # parse out the second part of the name after
    # the underscore character
    function_name = function_name.split("_")[1]
    # create a dictionary with the function's
    # purpose as the key and the value as
    # the return of the function that collects it
    return {function_name: str(platform.machine())}
```

::: {.fragment .fade style="margin-top: 0.5em; font-size: 0.9em;"}

- Use the `inspect` package to detect the name of the function
- Use the `platform` package to detect the CPU architecture
- Ensure that the function works in all execution environments!

:::
